---
title: "New_Haven_parcel_land_cover_summary"
author: "Dexter H. Locke, PhD"
date: "`r format(Sys.time())`"
output: html_document
editor_options: 
  chunk_output_type: console
---


  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# 0 load libraries and read in data----
```{r message=FALSE}
# Load libraries #### from Carly 
packs <-c('tidyverse'   # cuz
          , 'tidylog'   # prints out what was done in dplyr and tidr
          , 'janitor'   # cleans things up, also pipe-friendly cross-tabulations
          , 'sf'        # Simple Features, for spatial data support
          , 'mapview'   # web maps for zooming and panning around
          , 'parallel'  # parallel processing, vroom, vroom
          , 'tictoc'    # times things
          ) 
          

if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
install.packages(setdiff(packs, rownames(installed.packages())))
}

# load all packages at once.
vapply(packs, library, character.only = TRUE, logical(1), logical.return = TRUE, quietly = TRUE)


list.files()


mapviewOptions(fgb = FALSE) # fixes mapview (something about new versions.. )


# for reproducibility, we should have the same random draws. setting the seed ensures that is the case.
set.seed(19870630)


```



# 1 read in data

## A land cover raste
```{r}

system.time(lc_raster <- raster::raster('../../../URI_data/TreeCanopy_SCRCOG_2016/landcover_2016_scrcog.img'))
lc_raster

# lc_raster |> mapview()

```



## B parcel polygons
```{r}

list.files('../../../URI_data/')
st_layers('../../../URI_data/Connecticut_Parcels.gdb') # sort(unique(shp$TOWN))

tic();(
shp <- st_read('../../../URI_data/Connecticut_Parcels.gdb', 'deepgis_DEEP_PARCEL',
              query = 'SELECT * FROM "deepgis_DEEP_PARCEL" WHERE TOWN_NO = 93') %>% 
  # thanks @jayrobw via https://jayrobwilliams.com/posts/2020/09/spatial-sql !!
  #dplyr::filter(TOWN == 'New Haven') %>% 
  st_transform(crs = raster::crs(lc_raster)) %>% 
  rownames_to_column(var = 'id') #%>% 
  # as_Spatial()
);toc() # about 40 seconds with the dplyr::filter and about 8 with the SQL query

shp


```








## sand box
```{r eval=FALSE, include=FALSE}

```



```{r, citations}
lapply(packages, citation)
```

Last knit on `r format(Sys.time())`

```{r eval=FALSE, include=FALSE}
system.time(save.image(file = paste0('saved_sessions/New_Haven_street_trees_redlining_'
                                     , gsub('[[:punct:]]', '-', Sys.time()), '.RData')))
```


# END

